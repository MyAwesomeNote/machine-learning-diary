{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as functional\n",
    "\n",
    "\n",
    "import os, re, random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.821062500Z",
     "start_time": "2023-09-26T07:18:23.981306800Z"
    }
   },
   "id": "dd7021ea3cc65db5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word]  = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.825855700Z",
     "start_time": "2023-09-26T07:18:26.969042Z"
    }
   },
   "id": "be400681afb4c61e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def normalize_string(df, lang):\n",
    "    sentence = df[lang].str.lower()\n",
    "    sentence = sentence.str.replace(\"[^A-Za-z\\s]+\", \" \")\n",
    "    sentence = sentence.str.normalize(\"NFD\")\n",
    "    sentence = sentence.str.encode(\"ascii\", errors=\"ignore\").str.decode(\"utf-8\")\n",
    "    return sentence\n",
    "\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    sentence1 = normalize_string(df, lang1)\n",
    "    sentence2 = normalize_string(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    return pd.read_csv(loc, delimiter=\"\\t\", header=None, names=[lang1, lang2])\n",
    "\n",
    "def process_data(lang1, lang2):\n",
    "    df = read_file(\"../data/nlp/%s-%s.txt\" % (lang1, lang2), lang1, lang2)\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    in_lang = Lang()\n",
    "    out_lang = Lang()\n",
    "\n",
    "    _pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if len(sentence1[i].split()) < MAX_LENGTH and len(sentence2[i].split()) < MAX_LENGTH:\n",
    "            full = [sentence1[i], sentence2[i]]\n",
    "            in_lang.add_sentence(sentence1[i])\n",
    "            out_lang.add_sentence(sentence2[i])\n",
    "            _pairs.append(full)\n",
    "\n",
    "    return in_lang, out_lang, _pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.826400300Z",
     "start_time": "2023-09-26T07:18:26.979294900Z"
    }
   },
   "id": "a2045aa44656ea6d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def index_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes = index_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensor_from_pair(in_lang, out_lang, pair):\n",
    "    input_tensor = tensor_from_sentence(in_lang, pair[0])\n",
    "    output_tensor = tensor_from_sentence(out_lang, pair[1])\n",
    "    return input_tensor, output_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.827557800Z",
     "start_time": "2023-09-26T07:18:26.987773400Z"
    }
   },
   "id": "1dbe2bdccb795fd0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embed_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding= nn.Embedding(input_dim, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.828089500Z",
     "start_time": "2023-09-26T07:18:26.996552900Z"
    }
   },
   "id": "9e89560bb6d1962a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embed_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1)\n",
    "        embedded = functional.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.softmax(self.fc(output[0]))\n",
    "        return prediction, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.828626100Z",
     "start_time": "2023-09-26T07:18:27.006950100Z"
    }
   },
   "id": "dc739d57271bfdf0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, _device, max_len=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "\n",
    "        self.MAX_LENGTH = max_len\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = _device\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor, teacher_forcing_ratio=0.5):\n",
    "        input_length = input_tensor.size(0)\n",
    "        batch_size = target_tensor.shape[1]\n",
    "        target_length = target_tensor.shape[0]\n",
    "\n",
    "        vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_tensor[i])\n",
    "\n",
    "        decoder_hidden = encoder_hidden.unsqueeze(0).to(device)\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            for t in range(target_length):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                outputs[t] = decoder_output\n",
    "                decoder_input = target_tensor[t]\n",
    "\n",
    "        else:\n",
    "            for t in range(target_length):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                outputs[t] = decoder_output\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.830227400Z",
     "start_time": "2023-09-26T07:18:27.017219500Z"
    }
   },
   "id": "2b5b313febc76908"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def Model(_model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    output = _model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.833448700Z",
     "start_time": "2023-09-26T07:18:27.025523700Z"
    }
   },
   "id": "b0c1cb8888ac106d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train_model(_model, input_lang, output_lang, pairs, num_iteration=20000):\n",
    "    if not os.path.exists('./ckpt'):\n",
    "        os.makedirs('./ckpt')\n",
    "        \n",
    "    # if a model exists, load and print iteration\n",
    "    if os.path.isfile('./ckpt/nlp.pt'):\n",
    "        _model.load_state_dict(torch.load('./ckpt/nlp.pt'))\n",
    "        print(\"Model loaded\")\n",
    "        \n",
    "    _model.train()\n",
    "    optimizer = optim.SGD(_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "    training_pairs = [tensor_from_pair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for _ in range(num_iteration)]\n",
    "\n",
    "    for iter in range(1, num_iteration+1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(_model, input_tensor, target_tensor, optimizer, criterion)\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            average_loss = total_loss_iterations / 5000\n",
    "            total_loss_iterations = 0\n",
    "            print('%d %.4f' % (iter, average_loss ))\n",
    "            \n",
    "            # save\n",
    "            torch.save(_model.state_dict(), './ckpt/nlp.pt')\n",
    "            print(f\"Model saved at {iter} iteration\")\n",
    "\n",
    "    print(\"Model saved at last iteration\")    \n",
    "    torch.save(_model.state_dict(), './ckpt/nlp.pt')\n",
    "    \n",
    "    return _model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.833988500Z",
     "start_time": "2023-09-26T07:18:27.035127300Z"
    }
   },
   "id": "4df1074204f36a1d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def evaluate(_model, input_lang, output_lang, sentences):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentence(input_lang, sentences[0])\n",
    "        output_tensor = tensor_from_sentence(output_lang, sentences[1])\n",
    "        decoded_words = []\n",
    "        output = _model(input_tensor, output_tensor)\n",
    "\n",
    "        for ot in range(output.size(0)):\n",
    "            top_v, topi = output[ot].topk(1)\n",
    "\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "\n",
    "    return decoded_words\n",
    "\n",
    "def evaluate_randomly(_model, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('input {}'.format(pair[0]))\n",
    "        print('output {}'.format(pair[1]))\n",
    "        output_words = evaluate(_model, input_lang, output_lang, pair)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted {}'.format(output_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:18:27.834522700Z",
     "start_time": "2023-09-26T07:18:27.046347300Z"
    }
   },
   "id": "6d0692e38ee85489"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence [\"i don't want to shoot you.\", 'je ne veux pas te tirer dessus.']\n",
      "Input : 23194 Output : 39389\n",
      "Encoder(\n",
      "  (embedding): Embedding(23194, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(39389, 256)\n",
      "  (gru): GRU(256, 512)\n",
      "  (fc): Linear(in_features=512, out_features=39389, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "Model loaded\n",
      "5000 5.3314\n",
      "Model saved at 5000 iteration\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(encoder)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(decoder)\n\u001B[1;32m---> 25\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_iteration\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 22\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(_model, input_lang, output_lang, pairs, num_iteration)\u001B[0m\n\u001B[0;32m     20\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m training_pair[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     21\u001B[0m target_tensor \u001B[38;5;241m=\u001B[39m training_pair[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 22\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m total_loss_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5000\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[8], line 14\u001B[0m, in \u001B[0;36mModel\u001B[1;34m(_model, input_tensor, target_tensor, model_optimizer, criterion)\u001B[0m\n\u001B[0;32m     11\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m criterion(output[ot], target_tensor[ot])\n\u001B[0;32m     13\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 14\u001B[0m \u001B[43mmodel_optimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m/\u001B[39m num_iter\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m epoch_loss\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:76\u001B[0m, in \u001B[0;36mSGD.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m     72\u001B[0m momentum_buffer_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     74\u001B[0m has_sparse_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001B[1;32m---> 76\u001B[0m \u001B[43msgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43md_p_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmomentum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdampening\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdampening\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnesterov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnesterov\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# update momentum_buffers in state\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p, momentum_buffer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:222\u001B[0m, in \u001B[0;36msgd\u001B[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    220\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_sgd\n\u001B[1;32m--> 222\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m     \u001B[49m\u001B[43md_p_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdampening\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdampening\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m     \u001B[49m\u001B[43mnesterov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnesterov\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\sgd.py:325\u001B[0m, in \u001B[0;36m_multi_tensor_sgd\u001B[1;34m(params, grads, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001B[0m\n\u001B[0;32m    322\u001B[0m         device_grads \u001B[38;5;241m=\u001B[39m bufs\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m device_has_sparse_grad:\n\u001B[1;32m--> 325\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_foreach_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_grads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;66;03m# foreach APIs don't support sparse\u001B[39;00m\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(device_params)):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
    "\n",
    "randomize = random.choice(pairs)\n",
    "print('random sentence {}'.format(randomize))\n",
    "\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "print('Input : {} Output : {}'.format(input_size, output_size))\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 75000\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n",
    "model = train_model(model, input_lang, output_lang, pairs, num_iteration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:23:13.883225700Z",
     "start_time": "2023-09-26T07:18:27.054279400Z"
    }
   },
   "id": "6e60ffaf46f0894"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout=0.5, max_len=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_len)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = functional.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = functional.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T07:23:13.885353900Z",
     "start_time": "2023-09-26T07:23:13.885353900Z"
    }
   },
   "id": "2dfba3d14c117ea0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_iters(encoder, decoder, n_iters, print_every=1000, plot_every=1000):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)\n",
    "    \n",
    "    training_pairs = [tensor_from_pair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for _ in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = Model(encoder, decoder, input_tensor, target_tensor, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%d %.4f' % (iter, print_loss_avg))\n",
    "            \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-26T07:23:13.886216800Z"
    }
   },
   "id": "eea4679212cabafc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-26T07:23:13.887303300Z"
    }
   },
   "id": "ab6374a9e42f15b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
